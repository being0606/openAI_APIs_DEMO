{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy -y \n",
    "# !conda install -c conda-forge numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making API request data: 100%|██████████| 1000/1000 [00:00<00:00, 562993.83it/s]\n",
      "INFO:__main__:Total 1000 API requests are made!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_id': '1427_10_17_2', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4o', 'messages': [{'role': 'system', 'content': 'You are an expert in translating Hanja documents into English.\\nThe documents are written in Joseon, which is one of the Korean dynasties.\\nTranslate the input document into English with the following compact JSON format:\\n{\"translated\": {The translated document}}'}, {'role': 'user', 'content': '○右司諫金孝貞等上疏曰: 竊謂凡所施爲, 視歲豐歉。 比年以來, 水旱相仍, 禾稼不稔, 而今年正値農月, 旱乾爲甚, 殿下(霄) 旰軫念, 救荒恤民之政, 無不畢擧, 德至渥也。 今以忠淸、慶尙、全羅、江原、咸吉等道農事爲優, 許遣軍容敬差官, 將點兵船軍器, 以備不虞, 慮至深也。 然上項各道, 雖不若京畿、黃海、平安道之爲歉, 亦恐未至於豐稔也。 且他道之飢餓者, 將或轉而求食, 及其終也, 土着之民, 不免艱食之憂, 勢所必至, 其於點閱之際, 搔擾人民, 又非一端, 弊固不小。 伏望殿下姑停遣官, 待後豐年, 點考施行, 以慰民生。 上議于政府, 命停之。'}], 'max_tokens': 1000, 'temperature': 0.0, 'seed': 42}}\n"
     ]
    }
   ],
   "source": [
    "# 로거 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert in translating Hanja documents into English.\n",
    "The documents are written in Joseon, which is one of the Korean dynasties.\n",
    "Translate the input document into English with the following compact JSON format:\n",
    "{\"translated\": {The translated document}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# 이전에 생성한 데이터프레임 로드 (필요에 따라 경로 수정)\n",
    "df_sentences_filtered = pd.read_csv(\"../data/sentencePair_세종실록_filtered.csv\")\n",
    "df_sentences_filtered_sample = df_sentences_filtered.sample(1000, random_state=42)\n",
    "\n",
    "# target_data 생성\n",
    "target_data = df_sentences_filtered_sample.to_dict('records')\n",
    "\n",
    "# args 생성\n",
    "args = Namespace(\n",
    "    model='gpt-4o',  # 사용할 모델명\n",
    "    max_completion_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# make_api_request_data 함수 정의\n",
    "def make_api_request_data(target_data: List[Dict[str, Any]], args: Namespace) -> List[Dict[str, Any]]:\n",
    "    # https://platform.openai.com/docs/guides/batch/getting-started 참조\n",
    "    request_data = []\n",
    "\n",
    "    for data_idx, datum in enumerate(tqdm(target_data, desc=\"Making API request data\", mininterval=1)):\n",
    "        # custom_id 생성 (year, month, day, sentence_index 조합)\n",
    "        custom_id = f\"{datum['year']}_{datum['month']}_{datum['day']}_{datum['sentence_index']}\"\n",
    "\n",
    "        request_data.append(\n",
    "            {\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": args.model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": datum[\"hanja\"]},\n",
    "                    ],\n",
    "                    \"max_tokens\": args.max_completion_tokens,\n",
    "                    \"temperature\": args.temperature,\n",
    "                    \"seed\": args.seed\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    logger.info(f\"Total {len(request_data)} API requests are made!\")\n",
    "    return request_data\n",
    "\n",
    "# 함수 호출하여 API 요청 데이터 생성\n",
    "api_requests = make_api_request_data(target_data, args)\n",
    "\n",
    "# 결과 확인 (예시로 첫 번째 요청 데이터 출력)\n",
    "print(api_requests[0])\n",
    "\n",
    "# \"../data/ch02_batchinput.jsonl\", \"rb\" 해당경로에 저장\n",
    "with open(\"../data/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for request in api_requests:\n",
    "        f.write(json.dumps(request, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o-mini.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# file upload\u001b[39;00m\n\u001b[1;32m      8\u001b[0m batch_input_file \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m----> 9\u001b[0m   file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o-mini.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     10\u001b[0m   purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create a new batch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m client\u001b[38;5;241m.\u001b[39mbatches\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     15\u001b[0m     input_file_id\u001b[38;5;241m=\u001b[39mbatch_input_file\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     16\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     }\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HJ/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o-mini.jsonl'"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# file upload\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"../data/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o-mini.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# Create a new batch\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"조선왕조실록 중 세종실록 1000문장 번역\",\n",
    "    }\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "# Batch 객체들의 리스트를 가져옵니다.\n",
    "batches = client.batches.list().data\n",
    "\n",
    "# 각 배치의 상세 정보를 출력합니다.\n",
    "for batch in batches[:5]:\n",
    "    print(f\"Batch ID: {batch.id}\")\n",
    "    print(f\"Status: {batch.status}\")\n",
    "    print(f\"Created At: {batch.created_at}\")\n",
    "    print(f\"input_file_id: {batch.input_file_id}\")\n",
    "    print(f\"output_file_id: {batch.output_file_id}\")\n",
    "    print(\"------\")\n",
    "    \n",
    "\n",
    "# status를 60초에 한번씩 확인하고 'completed'일때까지 로그를 출력\n",
    "# status가 'completed'가 되면 루프를 탈출합니다.\n",
    "# 총 걸린 시간을 추가로 출력합니다.\n",
    "while True:\n",
    "  status = client.batches.retrieve(client.batches.list().data[0].id).status\n",
    "  print(\"time: \", time.strftime('%X', time.localtime()), \"   |    status: \", status)\n",
    "  if status == \"completed\":\n",
    "    break\n",
    "  time.sleep(60) # 60초에 한번씩 확인\n",
    "\n",
    "print(\"Total time: \", time.time() - start_time)\n",
    "\n",
    "\n",
    "# output file을 다운로드 받아서 출력\n",
    "file_response = client.files.content(client.batches.list().data[0].output_file_id).text.encode('utf-8').decode('unicode-escape')\n",
    "print(file_response)\n",
    "\n",
    "file_response[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: batch_674cec1cbee48190929cac2a3f8d8035\n",
      "Status: completed\n",
      "Created At: 1733094428\n",
      "input_file_id: file-GtaQcyhursUmMzCrwZqcg4\n",
      "output_file_id: file-KyBP7HotL1FCfyyBzmSNNi\n",
      "------\n",
      "Batch ID: batch_674cea18f7308190b8434a31c44c742a\n",
      "Status: completed\n",
      "Created At: 1733093913\n",
      "input_file_id: file-KWWGExKBdBqT71yvAjLTeX\n",
      "output_file_id: file-Tbb5nPoCtGkCs5ZFdmCJiE\n",
      "------\n",
      "Batch ID: batch_674ce81a4e2881908cf62316d25fc421\n",
      "Status: completed\n",
      "Created At: 1733093402\n",
      "input_file_id: file-CY5QRmsdwf4qWKdqC11o29\n",
      "output_file_id: file-UKx4DD3UPzxcZtpUA8pq5C\n",
      "------\n",
      "Batch ID: batch_674ce67a7534819083224a4590f28ce1\n",
      "Status: completed\n",
      "Created At: 1733092986\n",
      "input_file_id: file-DQqHndwKV5tV7UTNXfhvwL\n",
      "output_file_id: file-LLtT841NgCFziQHXtdY75h\n",
      "------\n",
      "Batch ID: batch_674ce48716e481909f12cf9373e04eab\n",
      "Status: completed\n",
      "Created At: 1733092487\n",
      "input_file_id: file-7jN2BYJF1Mtf2vJDErNnky\n",
      "output_file_id: file-UUTZd5Bzn7B1PKVWYW8XW6\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Batch 객체들의 리스트를 가져옵니다.\n",
    "batches = client.batches.list().data\n",
    "\n",
    "# 각 배치의 상세 정보를 출력합니다.\n",
    "for batch in batches[:5]:\n",
    "    print(f\"Batch ID: {batch.id}\")\n",
    "    print(f\"Status: {batch.status}\")\n",
    "    print(f\"Created At: {batch.created_at}\")\n",
    "    print(f\"input_file_id: {batch.input_file_id}\")\n",
    "    print(f\"output_file_id: {batch.output_file_id}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/batches/batch_674cec1cbee48190929cac2a3f8d8035 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(client.batches.list().data[0].id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-DQqHndwKV5tV7UTNXfhvwL/content \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\":\"0\",\"method\":\"POST\",\"url\":\"\\/v1\\/chat\\/completions\",\"body\":{\"model\":\"gpt-4o-2024-11-20\",\"messages\":[{\"role\":\"system\",\"content\":\"You are an expert in restoring damaged Hanja characters.\\n\\nInput Sentence: \\\"\\u25a1\\u25a1\\u25a1\\u6975, \\u6cbb\\u4e16\\u5b89\\u6c11.\\\"\\n\\nTasks:\\n1. Count the exact number of `\\u25a1` tokens in the sentence. Each `\\u25a1` must be counted individually.\\n2. Replace each `\\u25a1` with exactly one Hanja character. Ensure that no `\\u25a1` is left unprocessed and that each `\\u25a1` corresponds to exactly one Hanja character.\\n\\nStep-by-step output in JSON format:\\n{\\n  \\\"num_of_damage_token\\\": \\\"{Number of `\\u25a1` tokens}\\\",\\n  \\\"restorations\\\": [\\n    {\\\"damage_token\\\": \\\"\\u25a1 1\\\", \\\"restored_hanja\\\": \\\"{Restored Character 1}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 2\\\", \\\"restored_hanja\\\": \\\"{Restored Character 2}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 3\\\", \\\"restored_hanja\\\": \\\"{Restored Character 3}\\\"}\\n  ],\\n  \\\"restored_hanja\\\": \\\"{Restored Sentence}\\\",\\n}\"},{\"role\":\"user\",\"content\":\"\\u25a1\\u9662\\u5553\\u66f0, \\u660e\\u25a1\\u25a1\\u25a1\\u00b7\\u7d93\\u7b75, \\u53d6\\u7a1f. \\u50b3\\u66f0, \\u505c.\"}],\"max_tokens\":500,\"temperature\":0.0,\"seed\":42,\"response_format\":{\"type\":\"json_object\"}}}\n",
      "{\"custom_id\":\"1\",\"method\":\"POST\",\"url\":\"\\/v1\\/chat\\/completions\",\"body\":{\"model\":\"gpt-4o-2024-11-20\",\"messages\":[{\"role\":\"system\",\"content\":\"You are an expert in restoring damaged Hanja characters.\\n\\nInput Sentence: \\\"\\u25a1\\u25a1\\u25a1\\u6975, \\u6cbb\\u4e16\\u5b89\\u6c11.\\\"\\n\\nTasks:\\n1. Count the exact number of `\\u25a1` tokens in the sentence. Each `\\u25a1` must be counted individually.\\n2. Replace each `\\u25a1` with exactly one Hanja character. Ensure that no `\\u25a1` is left unprocessed and that each `\\u25a1` corresponds to exactly one Hanja character.\\n\\nStep-by-step output in JSON format:\\n{\\n  \\\"num_of_damage_token\\\": \\\"{Number of `\\u25a1` tokens}\\\",\\n  \\\"restorations\\\": [\\n    {\\\"damage_token\\\": \\\"\\u25a1 1\\\", \\\"restored_hanja\\\": \\\"{Restored Character 1}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 2\\\", \\\"restored_hanja\\\": \\\"{Restored Character 2}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 3\\\", \\\"restored_hanja\\\": \\\"{Restored Character 3}\\\"}\\n  ],\\n  \\\"restored_hanja\\\": \\\"{Restored Sentence}\\\",\\n}\"},{\"role\":\"user\",\"content\":\"\\u91d1\\u76f8\\u4f11\\u5553\\u66f0, \\u884c\\u5927\\u53f8\\u61b2\\u674e\\u25a1\\u25a1, \\u57f7\\u7fa9\\u5b8b\\u7a1a\\u572d, \\u6301\\u5e73\\u912d\\u9032\\u660e\\u5728\\u5916, \\u638c\\u4ee4\\u8d99\\u6649\\u548c\\u00b7\\u25a1\\u25a1\\u25a1, \\u6301\\u5e73\\u25a1\\u25a1\\u25a1\\u672a\\u8085\\u62dc, \\u76e3\\u5bdf\\u8336\\u6642\\u4e4b\\u610f, \\u6562\\u5553. \\u50b3\\u66f0, \\u77e5\\u9053.\"}],\"max_tokens\":500,\"temperature\":0.0,\"seed\":42,\"response_format\":{\"type\":\"json_object\"}}}\n",
      "{\"custom_id\":\"2\",\"method\":\"POST\",\"url\":\"\\/v1\\/chat\\/completions\",\"body\":{\"model\":\"gpt-4o-2024-11-20\",\"messages\":[{\"role\":\"system\",\"content\":\"You are an expert in restoring damaged Hanja characters.\\n\\nInput Sentence: \\\"\\u25a1\\u25a1\\u25a1\\u6975, \\u6cbb\\u4e16\\u5b89\\u6c11.\\\"\\n\\nTasks:\\n1. Count the exact number of `\\u25a1` tokens in the sentence. Each `\\u25a1` must be counted individually.\\n2. Replace each `\\u25a1` with exactly one Hanja character. Ensure that no `\\u25a1` is left unprocessed and that each `\\u25a1` corresponds to exactly one Hanja character.\\n\\nStep-by-step output in JSON format:\\n{\\n  \\\"num_of_damage_token\\\": \\\"{Number of `\\u25a1` tokens}\\\",\\n  \\\"restorations\\\": [\\n    {\\\"damage_token\\\": \\\"\\u25a1 1\\\", \\\"restored_hanja\\\": \\\"{Restored Character 1}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 2\\\", \\\"restored_hanja\\\": \\\"{Restored Character 2}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 3\\\", \\\"restored_hanja\\\": \\\"{Restored Character 3}\\\"}\\n  ],\\n  \\\"restored_hanja\\\": \\\"{Restored Sentence}\\\",\\n}\"},{\"role\":\"user\",\"content\":\"\\u4ee5\\u6460\\u620e\\u5343\\u6460\\u671b\\u7b52, \\u50b3\\u4e8e\\u674e\\u25a1\\u25a1\\u66f0, \\u4ecd\\u4efb.\"}],\"max_tokens\":500,\"temperature\":0.0,\"seed\":42,\"response_format\":{\"type\":\"json_object\"}}}\n",
      "{\"custom_id\":\"3\",\"method\":\"POST\",\"url\":\"\\/v1\\/chat\\/completions\",\"body\":{\"model\":\"gpt-4o-2024-11-20\",\"messages\":[{\"role\":\"system\",\"content\":\"You are an expert in restoring damaged Hanja characters.\\n\\nInput Sentence: \\\"\\u25a1\\u25a1\\u25a1\\u6975, \\u6cbb\\u4e16\\u5b89\\u6c11.\\\"\\n\\nTasks:\\n1. Count the exact number of `\\u25a1` tokens in the sentence. Each `\\u25a1` must be counted individually.\\n2. Replace each `\\u25a1` with exactly one Hanja character. Ensure that no `\\u25a1` is left unprocessed and that each `\\u25a1` corresponds to exactly one Hanja character.\\n\\nStep-by-step output in JSON format:\\n{\\n  \\\"num_of_damage_token\\\": \\\"{Number of `\\u25a1` tokens}\\\",\\n  \\\"restorations\\\": [\\n    {\\\"damage_token\\\": \\\"\\u25a1 1\\\", \\\"restored_hanja\\\": \\\"{Restored Character 1}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 2\\\", \\\"restored_hanja\\\": \\\"{Restored Character 2}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 3\\\", \\\"restored_hanja\\\": \\\"{Restored Character 3}\\\"}\\n  ],\\n  \\\"restored_hanja\\\": \\\"{Restored Sentence}\\\",\\n}\"},{\"role\":\"user\",\"content\":\"\\u53c8\\u8b80\\u6587\\u5b78\\u25a1\\u25a1\\u4e94\\u4e0a\\u66f8. \\u6279\\u4e0b.\"}],\"max_tokens\":500,\"temperature\":0.0,\"seed\":42,\"response_format\":{\"type\":\"json_object\"}}}\n",
      "{\"custom_id\":\"4\",\"method\":\"POST\",\"url\":\"\\/v1\\/chat\\/completions\",\"body\":{\"model\":\"gpt-4o-2024-11-20\",\"messages\":[{\"role\":\"system\",\"content\":\"You are an expert in restoring damaged Hanja characters.\\n\\nInput Sentence: \\\"\\u25a1\\u25a1\\u25a1\\u6975, \\u6cbb\\u4e16\\u5b89\\u6c11.\\\"\\n\\nTasks:\\n1. Count the exact number of `\\u25a1` tokens in the sentence. Each `\\u25a1` must be counted individually.\\n2. Replace each `\\u25a1` with exactly one Hanja character. Ensure that no `\\u25a1` is left unprocessed and that each `\\u25a1` corresponds to exactly one Hanja character.\\n\\nStep-by-step output in JSON format:\\n{\\n  \\\"num_of_damage_token\\\": \\\"{Number of `\\u25a1` tokens}\\\",\\n  \\\"restorations\\\": [\\n    {\\\"damage_token\\\": \\\"\\u25a1 1\\\", \\\"restored_hanja\\\": \\\"{Restored Character 1}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 2\\\", \\\"restored_hanja\\\": \\\"{Restored Character 2}\\\"},\\n    {\\\"damage_token\\\": \\\"\\u25a1 3\\\", \\\"restored_hanja\\\": \\\"{Restored Character 3}\\\"}\\n  ],\\n  \\\"restored_hanja\\\": \\\"{Restored Sentence}\\\",\\n}\"},{\"role\":\"user\",\"content\":\"\\u4e0a\\u5728\\u25a1\\u25a1\\u25a1. \\u505c\\u5e38\\u53c3\\u00b7\\u7d93\\u7b75.\"}],\"max_tokens\":500,\"temperature\":0.0,\"seed\":42,\"response_format\":{\"type\":\"json_object\"}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file_id = \"file-DQqHndwKV5tV7UTNXfhvwL\"\n",
    "# 출력 파일 내용 가져오기\n",
    "response = client.files.content(input_file_id)\n",
    "\n",
    "# 응답 내용을 UTF-8로 디코딩하여 문자열로 변환\n",
    "file_content = response.content.decode('utf-8')\n",
    "\n",
    "# 파일 내용 출력\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-UKx4DD3UPzxcZtpUA8pq5C/content \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"batch_req_674ce83628788190b5aaebfcdb9b98aa\", \"custom_id\": \"0\", \"response\": {\"status_code\": 200, \"request_id\": \"6da7a730f9478a5890031aa4f374c64d\", \"body\": {\"id\": \"chatcmpl-AZn3geR8d6VrHuCLgoQJzMAFCXdmU\", \"object\": \"chat.completion\", \"created\": 1733093424, \"model\": \"gpt-4o-2024-11-20\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\n  \\\"num_of_damage_token\\\": \\\"4\\\",\\n  \\\"restored_hanja\\\": \\\"\\u5167\\u9662\\u5553\\u66f0, \\u660e\\u65e8\\u5ba3\\u00b7\\u7d93\\u7b75, \\u53d6\\u7a1f. \\u50b3\\u66f0, \\u505c.\\\"\\n}\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 164, \"completion_tokens\": 46, \"total_tokens\": 210, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"system_fingerprint\": \"fp_24bb6f9e50\"}}, \"error\": null}\n",
      "{\"id\": \"batch_req_674ce8363a8c819083e0bb595bdaa005\", \"custom_id\": \"1\", \"response\": {\"status_code\": 200, \"request_id\": \"65ff6f18a166bbab5bbbbf896f219a94\", \"body\": {\"id\": \"chatcmpl-AZn3hMwPQRD4SIt8zo0hDyj3p3PMQ\", \"object\": \"chat.completion\", \"created\": 1733093425, \"model\": \"gpt-4o-2024-11-20\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\n  \\\"num_of_damage_token\\\": \\\"7\\\",\\n  \\\"restored_hanja\\\": \\\"\\u91d1\\u76f8\\u4f11\\u5553\\u66f0, \\u884c\\u5927\\u53f8\\u61b2\\u674e\\u656c, \\u57f7\\u7fa9\\u5b8b\\u7a1a\\u572d, \\u6301\\u5e73\\u912d\\u9032\\u660e\\u5728\\u5916, \\u638c\\u4ee4\\u8d99\\u6649\\u548c\\u00b7\\u5d07\\u5fb7, \\u6301\\u5e73\\u91d1\\u5b88\\u9053\\u672a\\u8085\\u62dc, \\u76e3\\u5bdf\\u8336\\u6642\\u4e4b\\u610f, \\u6562\\u5553. \\u50b3\\u66f0, \\u77e5\\u9053.\\\"\\n}\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 215, \"completion_tokens\": 99, \"total_tokens\": 314, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"system_fingerprint\": \"fp_24bb6f9e50\"}}, \"error\": null}\n",
      "{\"id\": \"batch_req_674ce83649548190b9946be941d825d1\", \"custom_id\": \"2\", \"response\": {\"status_code\": 200, \"request_id\": \"6b5b92dbd0d2a90daeeb1074dd90ca04\", \"body\": {\"id\": \"chatcmpl-AZn3jywRxD3IaVYIwbqcz0hzo6QOe\", \"object\": \"chat.completion\", \"created\": 1733093427, \"model\": \"gpt-4o-2024-11-20\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\n  \\\"num_of_damage_token\\\": \\\"2\\\",\\n  \\\"restored_hanja\\\": \\\"\\u4ee5\\u6460\\u620e\\u5343\\u6460\\u671b\\u7b52, \\u50b3\\u4e8e\\u674e\\u6210\\u5b97\\u66f0, \\u4ecd\\u4efb.\\\"\\n}\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 161, \"completion_tokens\": 44, \"total_tokens\": 205, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"system_fingerprint\": \"fp_24bb6f9e50\"}}, \"error\": null}\n",
      "{\"id\": \"batch_req_674ce8365d24819085c2f5e883ce18a2\", \"custom_id\": \"3\", \"response\": {\"status_code\": 200, \"request_id\": \"51dc51182517a5b9146b61e03cc79fef\", \"body\": {\"id\": \"chatcmpl-AZn3kZa4STnUzZkLenxazPIeD9OyV\", \"object\": \"chat.completion\", \"created\": 1733093428, \"model\": \"gpt-4o-2024-11-20\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\n  \\\"num_of_damage_token\\\": \\\"2\\\",\\n  \\\"restored_hanja\\\": \\\"\\u53c8\\u8b80\\u6587\\u5b78\\u7d93\\u53f2\\u4e94\\u4e0a\\u66f8. \\u6279\\u4e0b.\\\"\\n}\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 151, \"completion_tokens\": 34, \"total_tokens\": 185, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"system_fingerprint\": \"fp_24bb6f9e50\"}}, \"error\": null}\n",
      "{\"id\": \"batch_req_674ce83670708190917c687e6ed5a609\", \"custom_id\": \"4\", \"response\": {\"status_code\": 200, \"request_id\": \"54f05a165b7c873ed551e20956e025cf\", \"body\": {\"id\": \"chatcmpl-AZn3lmknofqpBra1CRp4JbMD3dNmQ\", \"object\": \"chat.completion\", \"created\": 1733093429, \"model\": \"gpt-4o-2024-11-20\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"{\\n  \\\"num_of_damage_token\\\": \\\"3\\\",\\n  \\\"restored_hanja\\\": \\\"\\u4e0a\\u5728\\u5bae\\u4e2d. \\u505c\\u5e38\\u53c3\\u00b7\\u7d93\\u7b75.\\\"\\n}\", \"refusal\": null}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 152, \"completion_tokens\": 34, \"total_tokens\": 186, \"prompt_tokens_details\": {\"cached_tokens\": 0, \"audio_tokens\": 0}, \"completion_tokens_details\": {\"reasoning_tokens\": 0, \"audio_tokens\": 0, \"accepted_prediction_tokens\": 0, \"rejected_prediction_tokens\": 0}}, \"system_fingerprint\": \"fp_24bb6f9e50\"}}, \"error\": null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_file_id = \"file-UKx4DD3UPzxcZtpUA8pq5C\"\n",
    "# 출력 파일 내용 가져오기\n",
    "response = client.files.content(output_file_id)\n",
    "\n",
    "# 응답 내용을 UTF-8로 디코딩하여 문자열로 변환\n",
    "file_content = response.content.decode('utf-8')\n",
    "\n",
    "# 파일 내용 출력\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# file upload\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"../data/batch_inputs/ch03_batchinput_sentencePair_세종실록_filtered_sampled_1000_gpt4o-mini.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# Create a new batch\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"조선왕조실록 중 세종실록 1000문장 번역\",\n",
    "    }\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "# Batch 객체들의 리스트를 가져옵니다.\n",
    "batches = client.batches.list().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: batch_674d0a21e67c8190b7a3f5bd86003cf1\n",
      "Status: validating\n",
      "Created At: 1733102114\n",
      "input_file_id: file-FcoLsag2jHfAroeo6eGXhv\n",
      "output_file_id: None\n",
      "------\n",
      "Batch ID: batch_674cec1cbee48190929cac2a3f8d8035\n",
      "Status: completed\n",
      "Created At: 1733094428\n",
      "input_file_id: file-GtaQcyhursUmMzCrwZqcg4\n",
      "output_file_id: file-KyBP7HotL1FCfyyBzmSNNi\n",
      "------\n",
      "Batch ID: batch_674cea18f7308190b8434a31c44c742a\n",
      "Status: completed\n",
      "Created At: 1733093913\n",
      "input_file_id: file-KWWGExKBdBqT71yvAjLTeX\n",
      "output_file_id: file-Tbb5nPoCtGkCs5ZFdmCJiE\n",
      "------\n",
      "Batch ID: batch_674ce81a4e2881908cf62316d25fc421\n",
      "Status: completed\n",
      "Created At: 1733093402\n",
      "input_file_id: file-CY5QRmsdwf4qWKdqC11o29\n",
      "output_file_id: file-UKx4DD3UPzxcZtpUA8pq5C\n",
      "------\n",
      "Batch ID: batch_674ce67a7534819083224a4590f28ce1\n",
      "Status: completed\n",
      "Created At: 1733092986\n",
      "input_file_id: file-DQqHndwKV5tV7UTNXfhvwL\n",
      "output_file_id: file-LLtT841NgCFziQHXtdY75h\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# 각 배치의 상세 정보를 출력합니다.\n",
    "for batch in batches[:5]:\n",
    "    print(f\"Batch ID: {batch.id}\")\n",
    "    print(f\"Status: {batch.status}\")\n",
    "    print(f\"Created At: {batch.created_at}\")\n",
    "    print(f\"input_file_id: {batch.input_file_id}\")\n",
    "    print(f\"output_file_id: {batch.output_file_id}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
